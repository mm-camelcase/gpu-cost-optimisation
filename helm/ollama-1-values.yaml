ollama:
  runtimeClassName: "nvidia"
  gpu:
    enabled: true
    type: 'nvidia'
    number: 1
  resources:
    limits:
      nvidia.com/gpu: 500m  # Allocates half of the GPU to this instance
    requests:
      nvidia.com/gpu: 500m  # Requests half of the GPU

   
  # -- List of models to pull at container startup
  models:
    pull:
      - llama2

extraEnv: 
  - name: NVIDIA_VISIBLE_DEVICES
    value: "all"
  - name: OLLAMA_DEBUG
    value: "1"

service:
  type: LoadBalancer
