ollama-mistral:
  gpu:
    enabled: true
    type: 'nvidia'
    number: 1  # Both instances share the same GPU
  models:
    pull:
      - mistral

ollama-llama2:
  gpu:
    enabled: true
    type: 'nvidia'
    number: 1  # Same shared GPU
  models:
    pull:
      - llama2

ingress:
  enabled: true
  className: "nginx"
  hosts:
    - host: ollama.camelcase.club
      paths:
        - path: /mistral
          pathType: Prefix
          backend:
            service:
              name: ollama-mistral
              port:
                number: 11434
        - path: /llama2
          pathType: Prefix
          backend:
            service:
              name: ollama-llama2
              port:
                number: 11434
