ollama:
  annotations:
    forceRedeploy: "{{ now | date \"20060102-150405\" }}"  # ðŸ‘ˆ Forces redeploy
  resources:
    limits:
      nvidia.com/gpu: 1
    requests:
      nvidia.com/gpu: 1  # âœ… Ensures GPU allocation
  extraEnv:
    - name: NVIDIA_VISIBLE_DEVICES
      value: all
    - name: NVIDIA_DRIVER_CAPABILITIES
      value: compute,utility
    - name: NVIDIA_REQUIRE_CUDA
      value: "cuda>=11.0"
    - name: CUDA_VISIBLE_DEVICES
      value: "0"
    - name: NVIDIA_CONTAINER_RUNTIME
      value: "nvidia"  # âœ… Ensures correct runtime
    - name: CUDA_MPS_PIPE_DIRECTORY
      value: "/tmp/nvidia-mps"
    - name: CUDA_MPS_LOG_DIRECTORY
      value: "/tmp/nvidia-log"
  securityContext:
    privileged: true
    capabilities:
      add: ["SYS_ADMIN"]
  gpu:
    enabled: true
    type: nvidia
    number: 1
    nvidiaResource: "nvidia.com/gpu"
  models:
    create:
      - name: mistral
        model: mistral
    pull:
      - name: llama2
        model: llama2
    run:
      - name: mistral
        model: mistral

# âœ… Force scheduling on GPU nodes
nodeSelector:
  node-type: gpu  # ðŸ‘ˆ Matches GPU nodegroup labels

# âœ… Tolerate taints applied to GPU nodes
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"

ingress:
  enabled: true
  className: traefik
  hosts:
  - host: ollama.3.248.93.23.nip.io
    paths:
    - path: /
      pathType: Prefix
