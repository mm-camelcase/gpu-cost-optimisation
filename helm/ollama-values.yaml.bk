ollama:
  # extraArgs:
  #   - "/bin/bash"
  #   - "-c"
  #   - |
  #     echo 'Checking CUDA libraries...';
  #     ls -l /usr/lib/x86_64-linux-gnu/ | grep libcuda;
  #     ls -l /usr/local/cuda/lib64/ | grep libcuda;
  #     nvidia-smi;
  #     echo 'Starting Ollama...';
  #     exec /app/ollama
  # extraVolumeMounts:
  #   - name: nvidia-driver-lib
  #     mountPath: /usr/lib/x86_64-linux-gnu
  #   - name: nvidia-driver-bin
  #     mountPath: /usr/local/nvidia/bin
  #   - name: cuda-lib
  #     mountPath: /usr/local/cuda/lib64
  #   - name: dev-nvidia
  #     mountPath: /dev/nvidia0
  #   - name: dev-nvidiactl
  #     mountPath: /dev/nvidiactl
  # extraVolumes:
  #   - name: nvidia-driver-lib
  #     hostPath:
  #       path: /usr/lib/x86_64-linux-gnu
  #   - name: nvidia-driver-bin
  #     hostPath:
  #       path: /usr/local/nvidia/bin
  #   - name: cuda-lib
  #     hostPath:
  #       path: /usr/local/cuda/lib64
  #   - name: dev-nvidia
  #     hostPath:
  #       path: /dev/nvidia0
  #   - name: dev-nvidiactl
  #     hostPath:
  #       path: /dev/nvidiactl
  annotations:
    forceRedeploy: "{{ now | date \"20060102-150405\" }}"  # ðŸ‘ˆ Forces redeploy
  resources:
    limits:
      nvidia.com/gpu: 1
    requests:
      nvidia.com/gpu: 1  # âœ… Ensures GPU allocation
  securityContext:
    privileged: true
    capabilities:
      add: ["SYS_ADMIN"]
  gpu:
    enabled: true
    type: nvidia
    number: 1
    nvidiaResource: "nvidia.com/gpu"
  models:
    create:
      - name: mistral
        model: mistral
    pull:
      - name: llama2
        model: llama2
    run:
      - name: mistral
        model: mistral

# âœ… Force scheduling on GPU nodes
nodeSelector:
  node-type: gpu  # ðŸ‘ˆ Matches GPU nodegroup labels

# âœ… Tolerate taints applied to GPU nodes
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"

ingress:
  enabled: true
  className: traefik
  hosts:
  - host: ollama.3.248.93.23.nip.io
    paths:
    - path: /
      pathType: Prefix

# extraEnv:
#   - name: NVIDIA_VISIBLE_DEVICES
#     value: all
#   - name: NVIDIA_DRIVER_CAPABILITIES
#     value: compute,utility
#   - name: NVIDIA_REQUIRE_CUDA
#     value: "cuda>=11.0"
#   - name: CUDA_VISIBLE_DEVICES
#     value: "0"
#   - name: NVIDIA_CONTAINER_RUNTIME
#     value: "nvidia"  # âœ… Ensures correct runtime
#   - name: CUDA_MPS_PIPE_DIRECTORY
#     value: "/tmp/nvidia-mps"
#   - name: CUDA_MPS_LOG_DIRECTORY
#     value: "/tmp/nvidia-log"
#   - name: OLLAMA_DEBUG
#     value: "1"
#   - name: PATH
#     value: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
#   - name: LD_LIBRARY_PATH
#     value: /usr/local/nvidia/lib:/usr/local/nvidia/lib64

